{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries. All of these packages are in the requirements.txt file accompanying this project. As best practice, \n",
    "## we recommend running this in an isolated venv.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openpyxl\n",
    "import ast\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import contextily as cx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup\n",
    "These variables are global to set the geographies, year, database, for our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The geography_code is the census fips code in str format for the main geography for the rental housing needs assessment.\n",
    "geography_city = '4819000'\n",
    "geography_metro = 'c19100'\n",
    "geography_county = '48113'\n",
    "## The most recent year that the ACS / PUMS data is available. \n",
    "acs_year = 2022\n",
    "## This report pulls from a database developed by HR&A for these functions. Each figure pulls from one or more tables in the database \n",
    "## and are in the format \"prefix/\"+SOURCE_TABLENAME_DESCRIPTION.csv\n",
    "\n",
    "url_prefix = \"https://housing-needs-assessment-data.s3.amazonaws.com/\"\n",
    "\n",
    "## The name of the geography, pulled from our crosswalk file\n",
    "names = pd.read_csv('https://housing-needs-assessment-data.s3.amazonaws.com/resources/geo_relatedgeo_crosswalk.csv', converters={'geo_id':str})\n",
    "geo_name = names[(names['geo_id'] == geography_city) & (~names['related_geo_id'].astype(str).str.startswith(\"p\").fillna(False))]['geo_name'].iloc[0]\n",
    "\n",
    "names = names.drop_duplicates(subset=['geo_id', 'geo_name'])[['geo_id','geo_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataset(dataset_name, geography_set, years):\n",
    "    df = pd.read_csv(url_prefix+dataset_name+'.csv', converters = {'geo_id':str})\n",
    "    df = df[(df['geo_id'].isin(geography_set)) & (df['year'].isin(years))]\n",
    "    return df\n",
    "\n",
    "def write_to_csv(source, section, folder, name):\n",
    "    \n",
    "    file_path = section + \"_\" + folder + \"/\" + name + \".csv\"\n",
    "    combined.to_csv(file_path, index=False)\n",
    "    with open(file_path,'a') as f:\n",
    "        f.write('\\n'+\"Source: \" + source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 2: City of Dallas Population (1990-2022) [p.25]\n",
    "Source: Decennial_Population (Census) and B01003 (American Communities Survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Figure 2 combines decennial with ACS data for a historic review of population. \u001b[39;00m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m filter_dataset(\n\u001b[1;32m      4\u001b[0m     dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDECENNIAL_Population\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     geography_set \u001b[38;5;241m=\u001b[39m [geography_city],\n\u001b[1;32m      6\u001b[0m     years \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1990\u001b[39m,\u001b[38;5;241m2000\u001b[39m,\u001b[38;5;241m2010\u001b[39m]\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m xf \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mACS_B01003_Population\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeography_set\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mgeography_city\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43myears\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43macs_year\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 2\u001b[0m, in \u001b[0;36mfilter_dataset\u001b[0;34m(dataset_name, geography_set, years)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter_dataset\u001b[39m(dataset_name, geography_set, years):\n\u001b[0;32m----> 2\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_prefix\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeo_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeo_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(geography_set)) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(years))]\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/repos/cpal-hna-report/cpal/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/cpal-hna-report/cpal/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/repos/cpal-hna-report/cpal/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/cpal-hna-report/cpal/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/repos/cpal-hna-report/cpal/lib/python3.12/site-packages/pandas/io/common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m~/repos/cpal-hna-report/cpal/lib/python3.12/site-packages/pandas/io/common.py:389\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n\u001b[1;32m    388\u001b[0m             compression \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m--> 389\u001b[0m         reader \u001b[38;5;241m=\u001b[39m BytesIO(\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m IOArgs(\n\u001b[1;32m    391\u001b[0m         filepath_or_buffer\u001b[38;5;241m=\u001b[39mreader,\n\u001b[1;32m    392\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m         mode\u001b[38;5;241m=\u001b[39mfsspec_mode,\n\u001b[1;32m    396\u001b[0m     )\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_fsspec_url(filepath_or_buffer):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:495\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead:\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:640\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[1;32m    634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 640\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[1;32m    642\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Figure 2 combines decennial with ACS data for a historic review of population. \n",
    "\n",
    "df = filter_dataset(\n",
    "    dataset_name = 'DECENNIAL_Population',\n",
    "    geography_set = [geography_city],\n",
    "    years = [1990,2000,2010]\n",
    ")\n",
    "\n",
    "xf = filter_dataset(\n",
    "    dataset_name = 'ACS_B01003_Population',\n",
    "    geography_set = [geography_city],\n",
    "    years = [acs_year]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>geo_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>1006877</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>1188580</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>1197816</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>1300642</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  population geo_name\n",
       "0  1990     1006877   Dallas\n",
       "1  2000     1188580   Dallas\n",
       "2  2010     1197816   Dallas\n",
       "3  2022     1300642   Dallas"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join and merge dataframes\n",
    "df = pd.concat([df, xf], ignore_index=True)\n",
    "df = df.sort_values(\"year\").reset_index(drop=True)\n",
    "df = df.merge(names, on='geo_id')\n",
    "df.drop(columns='geo_id',inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>year</th>\n",
       "      <th>geo_name</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>1006877</td>\n",
       "      <td>1188580</td>\n",
       "      <td>1197816</td>\n",
       "      <td>1300642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "year geo_name     1990     2000     2010     2022\n",
       "0      Dallas  1006877  1188580  1197816  1300642"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### For easier chart creation, we pivot the data to have years as columns for Excel\n",
    "xf = df.pivot(index='geo_name', columns='year', values='population')\n",
    "xf = xf.reset_index()\n",
    "xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export completed dataframe to folder\n",
    "file_path = 'DO_completed_csvs/figure1_2.csv'\n",
    "title = 'Source: Decennial 1990 & ACS 2022 Population'\n",
    "xf.to_csv(file_path, index=False)\n",
    "\n",
    "# append the data source to the dataframe\n",
    "with open(file_path, 'a') as f:\n",
    "    f.write('\\n' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 3: Comparative Population Growth (1990-2022)[p.25]\n",
    "Source: Decennial_Population (Census) and B01003 (American Communities Survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_dataset(\n",
    "    dataset_name = 'DECENNIAL_Population',\n",
    "    geography_set = [geography_city, geography_county, geography_metro],\n",
    "    years = [1990,2000,2010]\n",
    ")\n",
    "\n",
    "xf = filter_dataset(\n",
    "    dataset_name = 'ACS_B01003_Population',\n",
    "    geography_set = [geography_city, geography_county, geography_metro],\n",
    "    years = [2022]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>geo_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48113</td>\n",
       "      <td>1990</td>\n",
       "      <td>1852810</td>\n",
       "      <td>Dallas County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4819000</td>\n",
       "      <td>1990</td>\n",
       "      <td>1006877</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c19100</td>\n",
       "      <td>1990</td>\n",
       "      <td>3984437</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48113</td>\n",
       "      <td>2000</td>\n",
       "      <td>2218899</td>\n",
       "      <td>Dallas County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4819000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1188580</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c19100</td>\n",
       "      <td>2000</td>\n",
       "      <td>5156217</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48113</td>\n",
       "      <td>2010</td>\n",
       "      <td>2368139</td>\n",
       "      <td>Dallas County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4819000</td>\n",
       "      <td>2010</td>\n",
       "      <td>1197816</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c19100</td>\n",
       "      <td>2010</td>\n",
       "      <td>6366542</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c19100</td>\n",
       "      <td>2022</td>\n",
       "      <td>7673379</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4819000</td>\n",
       "      <td>2022</td>\n",
       "      <td>1300642</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48113</td>\n",
       "      <td>2022</td>\n",
       "      <td>2604053</td>\n",
       "      <td>Dallas County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     geo_id  year  population                         geo_name\n",
       "0     48113  1990     1852810                    Dallas County\n",
       "1   4819000  1990     1006877                           Dallas\n",
       "2    c19100  1990     3984437  Dallas-Fort Worth-Arlington, TX\n",
       "3     48113  2000     2218899                    Dallas County\n",
       "4   4819000  2000     1188580                           Dallas\n",
       "5    c19100  2000     5156217  Dallas-Fort Worth-Arlington, TX\n",
       "6     48113  2010     2368139                    Dallas County\n",
       "7   4819000  2010     1197816                           Dallas\n",
       "8    c19100  2010     6366542  Dallas-Fort Worth-Arlington, TX\n",
       "9    c19100  2022     7673379  Dallas-Fort Worth-Arlington, TX\n",
       "10  4819000  2022     1300642                           Dallas\n",
       "11    48113  2022     2604053                    Dallas County"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join and merge dataframes\n",
    "df = pd.concat([df, xf], ignore_index=True)\n",
    "df = df.sort_values(\"year\").reset_index(drop=True)\n",
    "df = df.merge(names, on='geo_id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>geo_name</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990</td>\n",
       "      <td>1852810</td>\n",
       "      <td>Dallas County</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990</td>\n",
       "      <td>1006877</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990</td>\n",
       "      <td>3984437</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>2218899</td>\n",
       "      <td>Dallas County</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1188580</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000</td>\n",
       "      <td>5156217</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010</td>\n",
       "      <td>2368139</td>\n",
       "      <td>Dallas County</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010</td>\n",
       "      <td>1197816</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010</td>\n",
       "      <td>6366542</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022</td>\n",
       "      <td>7673379</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022</td>\n",
       "      <td>1300642</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022</td>\n",
       "      <td>2604053</td>\n",
       "      <td>Dallas County</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  population                         geo_name  index\n",
       "0   1990     1852810                    Dallas County    100\n",
       "1   1990     1006877                           Dallas    100\n",
       "2   1990     3984437  Dallas-Fort Worth-Arlington, TX    100\n",
       "3   2000     2218899                    Dallas County    119\n",
       "4   2000     1188580                           Dallas    118\n",
       "5   2000     5156217  Dallas-Fort Worth-Arlington, TX    129\n",
       "6   2010     2368139                    Dallas County    127\n",
       "7   2010     1197816                           Dallas    118\n",
       "8   2010     6366542  Dallas-Fort Worth-Arlington, TX    159\n",
       "9   2022     7673379  Dallas-Fort Worth-Arlington, TX    192\n",
       "10  2022     1300642                           Dallas    129\n",
       "11  2022     2604053                    Dallas County    140"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate population growth\n",
    "\n",
    "def calculate_index(row, base_pop):\n",
    "    return 100 * row['population'] / base_pop\n",
    "\n",
    "for geo_id in df['geo_id'].unique():\n",
    "    base_pop = df[(df['geo_id'] == geo_id) & (df['year'] == 1990)]['population'].values[0]\n",
    "    df.loc[df['geo_id'] == geo_id, 'index'] = df[df['geo_id'] == geo_id].apply(calculate_index, axis=1, base_pop=base_pop)\n",
    "df['index'] = df['index'].astype(int)\n",
    "df.drop(columns='geo_id',inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>geo_name</th>\n",
       "      <th colspan=\"4\" halign=\"left\">population</th>\n",
       "      <th colspan=\"4\" halign=\"left\">index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>2022</th>\n",
       "      <th>1990</th>\n",
       "      <th>2000</th>\n",
       "      <th>2010</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>1006877</td>\n",
       "      <td>1188580</td>\n",
       "      <td>1197816</td>\n",
       "      <td>1300642</td>\n",
       "      <td>100</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dallas County</td>\n",
       "      <td>1852810</td>\n",
       "      <td>2218899</td>\n",
       "      <td>2368139</td>\n",
       "      <td>2604053</td>\n",
       "      <td>100</td>\n",
       "      <td>119</td>\n",
       "      <td>127</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>3984437</td>\n",
       "      <td>5156217</td>\n",
       "      <td>6366542</td>\n",
       "      <td>7673379</td>\n",
       "      <td>100</td>\n",
       "      <td>129</td>\n",
       "      <td>159</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             geo_name population                             \\\n",
       "year                                        1990     2000     2010     2022   \n",
       "0                              Dallas    1006877  1188580  1197816  1300642   \n",
       "1                       Dallas County    1852810  2218899  2368139  2604053   \n",
       "2     Dallas-Fort Worth-Arlington, TX    3984437  5156217  6366542  7673379   \n",
       "\n",
       "     index                 \n",
       "year  1990 2000 2010 2022  \n",
       "0      100  118  118  129  \n",
       "1      100  119  127  140  \n",
       "2      100  129  159  192  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pivot the dataframe \n",
    "xf = df.pivot(index='geo_name', columns='year', values=['population', 'index'])\n",
    "xf = xf.reset_index()\n",
    "xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export completed dataframe to folder\n",
    "file_path = 'DO_completed_csvs/figure1_3.csv'\n",
    "title = 'Source: Decennial 1990 & ACS 2022 Population'\n",
    "xf.to_csv(file_path, index=True)\n",
    "\n",
    "# append the data source to the dataframe\n",
    "with open(file_path, 'a') as f:\n",
    "    f.write('\\n' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 4: City of Dallas Comparative Population Growth (1990-2022) Cities with population 500,000 or greater [p.26]\n",
    "**Source:** Decennial_Population (Census) and B01003 (American Communities Survey)\n",
    "\n",
    "**Note:** Place definitions have changed since 1990. We use a reference here named 1990_places to match the old definitions to new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull data\n",
    "file_path = 'references/1990_places.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "pop = pd.read_csv(url_prefix + 'ACS_B01003_Population.csv', converters = {'geo_id':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/p4h692fs2850l4jh7f7_qq9r0000gr/T/ipykernel_4157/431022363.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Standardized_Name'] = filtered_df['Geo_QName'].str.replace(' city', '', regex=False).str.replace(' (remainder)', '', regex=False).str.split(',').str[0]\n"
     ]
    }
   ],
   "source": [
    "# filter to only keep cities with population 500,000 or greater\n",
    "pop = pop.merge(names, on='geo_id')\n",
    "pop = pop[(pop['year'] == 2022) & (pop['geo_id'].str.len() == 7) & (pop['population'] >= 500000)]\n",
    "pop = pop.rename(columns={'population':'pop2022'})\n",
    "\n",
    "##Standardizing these names to match the 1990 data with current ACS data\n",
    "geo_name = ['Fresno city, California', 'Los Angeles city, California', 'Mesa city, Arizona', 'Phoenix city, Arizona', 'Tucson city, Arizona', 'Sacramento city, California', 'San Diego city, California', 'San Francisco city, California', 'San Jose city, California', 'Denver city, Colorado', 'Washington city, District of Columbia', 'Jacksonville city (remainder), Florida', 'Chicago city, Illinois', 'Louisville city, Kentucky', 'Indianapolis city (remainder), Indiana', 'Baltimore city, Maryland', 'Boston city, Massachusetts', 'Detroit city, Michigan', 'Kansas City city, Missouri', 'Las Vegas city, Nevada', 'Albuquerque city, New Mexico', 'New York city, New York', 'Charlotte city, North Carolina', 'Columbus city, Ohio', 'Oklahoma City city, Oklahoma', 'Portland city, Oregon', 'Philadelphia city, Pennsylvania', 'Memphis city, Tennessee', 'Nashville-Davidson (remainder), Tennessee', 'Austin city, Texas', 'Dallas city, Texas', 'El Paso city, Texas', 'Fort Worth city, Texas', 'Houston city, Texas', 'San Antonio city, Texas', 'Seattle city, Washington', 'Milwaukee city, Wisconsin']\n",
    "filtered_df = df[df['Geo_QName'].isin(geo_name)]\n",
    "filtered_df['Standardized_Name'] = filtered_df['Geo_QName'].str.replace(' city', '', regex=False).str.replace(' (remainder)', '', regex=False).str.split(',').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/p4h692fs2850l4jh7f7_qq9r0000gr/T/ipykernel_4157/1388576424.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['temp_key'] = filtered_df['Standardized_Name'].str[:5]\n"
     ]
    }
   ],
   "source": [
    "# create temporary key columns for the first three characters\n",
    "pop['temp_key'] = pop['geo_name'].str[:5]\n",
    "filtered_df['temp_key'] = filtered_df['Standardized_Name'].str[:5]\n",
    "\n",
    "# perform the merge based on the temporary keys\n",
    "merged_df = pd.merge(pop, filtered_df, on='temp_key', how='inner')\n",
    "\n",
    "# drop the temporary key columns\n",
    "merged_df.drop('temp_key', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop2022</th>\n",
       "      <th>Geo_QName</th>\n",
       "      <th>pop1990</th>\n",
       "      <th>population growth_prc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8622467</td>\n",
       "      <td>New York city, New York</td>\n",
       "      <td>7322564</td>\n",
       "      <td>17.752020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3881041</td>\n",
       "      <td>Los Angeles city, California</td>\n",
       "      <td>3485398</td>\n",
       "      <td>11.351444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2721914</td>\n",
       "      <td>Chicago city, Illinois</td>\n",
       "      <td>2783726</td>\n",
       "      <td>-2.220477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2296253</td>\n",
       "      <td>Houston city, Texas</td>\n",
       "      <td>1630553</td>\n",
       "      <td>40.826640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1609456</td>\n",
       "      <td>Phoenix city, Arizona</td>\n",
       "      <td>983403</td>\n",
       "      <td>63.661896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1593208</td>\n",
       "      <td>Philadelphia city, Pennsylvania</td>\n",
       "      <td>1585577</td>\n",
       "      <td>0.481276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1445662</td>\n",
       "      <td>San Antonio city, Texas</td>\n",
       "      <td>935933</td>\n",
       "      <td>54.462125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1383987</td>\n",
       "      <td>San Diego city, California</td>\n",
       "      <td>1110549</td>\n",
       "      <td>24.621876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1300642</td>\n",
       "      <td>Dallas city, Texas</td>\n",
       "      <td>1006877</td>\n",
       "      <td>29.175858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1001176</td>\n",
       "      <td>San Jose city, California</td>\n",
       "      <td>782248</td>\n",
       "      <td>27.987032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>958202</td>\n",
       "      <td>Austin city, Texas</td>\n",
       "      <td>465622</td>\n",
       "      <td>105.789675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>950203</td>\n",
       "      <td>Jacksonville city (remainder), Florida</td>\n",
       "      <td>635230</td>\n",
       "      <td>49.584088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>924663</td>\n",
       "      <td>Fort Worth city, Texas</td>\n",
       "      <td>447619</td>\n",
       "      <td>106.573671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>902449</td>\n",
       "      <td>Columbus city, Ohio</td>\n",
       "      <td>632910</td>\n",
       "      <td>42.587256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>882006</td>\n",
       "      <td>Indianapolis city (remainder), Indiana</td>\n",
       "      <td>731327</td>\n",
       "      <td>20.603506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>875045</td>\n",
       "      <td>Charlotte city, North Carolina</td>\n",
       "      <td>395934</td>\n",
       "      <td>121.007794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>851036</td>\n",
       "      <td>San Francisco city, California</td>\n",
       "      <td>723959</td>\n",
       "      <td>17.553066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>734603</td>\n",
       "      <td>Seattle city, Washington</td>\n",
       "      <td>516259</td>\n",
       "      <td>42.293500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>710800</td>\n",
       "      <td>Denver city, Colorado</td>\n",
       "      <td>467610</td>\n",
       "      <td>52.007014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>684103</td>\n",
       "      <td>Nashville-Davidson (remainder), Tennessee</td>\n",
       "      <td>488374</td>\n",
       "      <td>40.077686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>681088</td>\n",
       "      <td>Oklahoma City city, Oklahoma</td>\n",
       "      <td>444719</td>\n",
       "      <td>53.150191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>677181</td>\n",
       "      <td>El Paso city, Texas</td>\n",
       "      <td>515342</td>\n",
       "      <td>31.404194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>670587</td>\n",
       "      <td>Washington city, District of Columbia</td>\n",
       "      <td>606900</td>\n",
       "      <td>10.493821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>665945</td>\n",
       "      <td>Boston city, Massachusetts</td>\n",
       "      <td>574283</td>\n",
       "      <td>15.961120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>646101</td>\n",
       "      <td>Portland city, Oregon</td>\n",
       "      <td>437319</td>\n",
       "      <td>47.741351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>644835</td>\n",
       "      <td>Las Vegas city, Nevada</td>\n",
       "      <td>258295</td>\n",
       "      <td>149.650593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>636787</td>\n",
       "      <td>Detroit city, Michigan</td>\n",
       "      <td>1027974</td>\n",
       "      <td>-38.054173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>630027</td>\n",
       "      <td>Memphis city, Tennessee</td>\n",
       "      <td>610337</td>\n",
       "      <td>3.226087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>629176</td>\n",
       "      <td>Louisville city, Kentucky</td>\n",
       "      <td>269063</td>\n",
       "      <td>133.839658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>584548</td>\n",
       "      <td>Baltimore city, Maryland</td>\n",
       "      <td>736014</td>\n",
       "      <td>-20.579228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>573299</td>\n",
       "      <td>Milwaukee city, Wisconsin</td>\n",
       "      <td>628088</td>\n",
       "      <td>-8.723141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>562551</td>\n",
       "      <td>Albuquerque city, New Mexico</td>\n",
       "      <td>384736</td>\n",
       "      <td>46.217406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>541528</td>\n",
       "      <td>Fresno city, California</td>\n",
       "      <td>354202</td>\n",
       "      <td>52.886771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>541033</td>\n",
       "      <td>Tucson city, Arizona</td>\n",
       "      <td>405390</td>\n",
       "      <td>33.459878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>523600</td>\n",
       "      <td>Sacramento city, California</td>\n",
       "      <td>369365</td>\n",
       "      <td>41.756799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>505958</td>\n",
       "      <td>Kansas City city, Missouri</td>\n",
       "      <td>435146</td>\n",
       "      <td>16.273159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>503390</td>\n",
       "      <td>Mesa city, Arizona</td>\n",
       "      <td>288091</td>\n",
       "      <td>74.732984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pop2022                                  Geo_QName  pop1990  \\\n",
       "25  8622467                    New York city, New York  7322564   \n",
       "29  3881041               Los Angeles city, California  3485398   \n",
       "33  2721914                     Chicago city, Illinois  2783726   \n",
       "17  2296253                        Houston city, Texas  1630553   \n",
       "6   1609456                      Phoenix city, Arizona   983403   \n",
       "32  1593208            Philadelphia city, Pennsylvania  1585577   \n",
       "7   1445662                    San Antonio city, Texas   935933   \n",
       "23  1383987                 San Diego city, California  1110549   \n",
       "21  1300642                         Dallas city, Texas  1006877   \n",
       "22  1001176                  San Jose city, California   782248   \n",
       "4    958202                         Austin city, Texas   465622   \n",
       "11   950203     Jacksonville city (remainder), Florida   635230   \n",
       "3    924663                     Fort Worth city, Texas   447619   \n",
       "14   902449                        Columbus city, Ohio   632910   \n",
       "24   882006     Indianapolis city (remainder), Indiana   731327   \n",
       "2    875045             Charlotte city, North Carolina   395934   \n",
       "26   851036             San Francisco city, California   723959   \n",
       "15   734603                   Seattle city, Washington   516259   \n",
       "10   710800                      Denver city, Colorado   467610   \n",
       "18   684103  Nashville-Davidson (remainder), Tennessee   488374   \n",
       "8    681088               Oklahoma City city, Oklahoma   444719   \n",
       "20   677181                        El Paso city, Texas   515342   \n",
       "30   670587      Washington city, District of Columbia   606900   \n",
       "28   665945                 Boston city, Massachusetts   574283   \n",
       "12   646101                      Portland city, Oregon   437319   \n",
       "0    644835                     Las Vegas city, Nevada   258295   \n",
       "36   636787                     Detroit city, Michigan  1027974   \n",
       "31   630027                    Memphis city, Tennessee   610337   \n",
       "1    629176                  Louisville city, Kentucky   269063   \n",
       "35   584548                   Baltimore city, Maryland   736014   \n",
       "34   573299                  Milwaukee city, Wisconsin   628088   \n",
       "13   562551               Albuquerque city, New Mexico   384736   \n",
       "9    541528                    Fresno city, California   354202   \n",
       "19   541033                       Tucson city, Arizona   405390   \n",
       "16   523600                Sacramento city, California   369365   \n",
       "27   505958                 Kansas City city, Missouri   435146   \n",
       "5    503390                         Mesa city, Arizona   288091   \n",
       "\n",
       "    population growth_prc  \n",
       "25              17.752020  \n",
       "29              11.351444  \n",
       "33              -2.220477  \n",
       "17              40.826640  \n",
       "6               63.661896  \n",
       "32               0.481276  \n",
       "7               54.462125  \n",
       "23              24.621876  \n",
       "21              29.175858  \n",
       "22              27.987032  \n",
       "4              105.789675  \n",
       "11              49.584088  \n",
       "3              106.573671  \n",
       "14              42.587256  \n",
       "24              20.603506  \n",
       "2              121.007794  \n",
       "26              17.553066  \n",
       "15              42.293500  \n",
       "10              52.007014  \n",
       "18              40.077686  \n",
       "8               53.150191  \n",
       "20              31.404194  \n",
       "30              10.493821  \n",
       "28              15.961120  \n",
       "12              47.741351  \n",
       "0              149.650593  \n",
       "36             -38.054173  \n",
       "31               3.226087  \n",
       "1              133.839658  \n",
       "35             -20.579228  \n",
       "34              -8.723141  \n",
       "13              46.217406  \n",
       "9               52.886771  \n",
       "19              33.459878  \n",
       "16              41.756799  \n",
       "27              16.273159  \n",
       "5               74.732984  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate population growth\n",
    "merged_df['population growth_prc'] = ((merged_df['pop2022'] - merged_df['pop1990']) / merged_df['pop1990'])*100\n",
    "merged_df = merged_df.sort_values(\"population growth_prc\", ascending = False).reset_index(drop=True)\n",
    "merged_df.drop(columns=['geo_id', 'year', 'geo_name', 'Geo_NAME', 'Geo_FIPS', 'Standardized_Name'], inplace=True)\n",
    "merged_df.sort_values('pop2022', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export completed dataframe to folder\n",
    "file_path = 'DO_completed_csvs/figure1_4.csv'\n",
    "title = 'Source: 1990 Census gazetteer files & ACS 2022 Population'\n",
    "merged_df.to_csv(file_path, index=False)\n",
    "\n",
    "# append the data source to the dataframe\n",
    "with open(file_path, 'a') as f:\n",
    "    f.write('\\n' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 5: Dallas-Fort Worth Metro Comparative Population Growth (1990-2022) Metro Areas (CBSAs) with population 1,500,000 or greater [p.26]\n",
    "**Source:** Decennial_Population (Census) and B01003 (American Communities Survey)\n",
    "\n",
    "**Note:** Place definitions have changed since 1990. We use a reference here named 1990_places to match the old definitions to new ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull data\n",
    "df = pd.read_csv(url_prefix + 'DECENNIAL_Population.csv', converters = {'geo_id':str})\n",
    "xf = pd.read_csv(url_prefix + 'ACS_B01003_Population.csv', converters = {'geo_id':str})\n",
    "## Crosswalk for Counties to CBSAS\n",
    "xwalk = pd.read_csv(url_prefix + 'resources/county_cbsa_xwalk.csv', converters={'county': str, 'cbsa':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop2022</th>\n",
       "      <th>pop1990</th>\n",
       "      <th>growth_percentage</th>\n",
       "      <th>geo_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2265926</td>\n",
       "      <td>741459</td>\n",
       "      <td>205.603681</td>\n",
       "      <td>Las Vegas-Henderson-Paradise, NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6123949</td>\n",
       "      <td>2119006</td>\n",
       "      <td>189.001022</td>\n",
       "      <td>Miami-Fort Lauderdale-Pompano Beach, FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2296377</td>\n",
       "      <td>846227</td>\n",
       "      <td>171.366548</td>\n",
       "      <td>Austin-Round Rock-Georgetown, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2679298</td>\n",
       "      <td>1224852</td>\n",
       "      <td>118.744632</td>\n",
       "      <td>Orlando-Kissimmee-Sanford, FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4864209</td>\n",
       "      <td>2238480</td>\n",
       "      <td>117.299641</td>\n",
       "      <td>Phoenix-Mesa-Chandler, AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6094752</td>\n",
       "      <td>3083843</td>\n",
       "      <td>97.634964</td>\n",
       "      <td>Atlanta-Sandy Springs-Alpharetta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2668688</td>\n",
       "      <td>1365184</td>\n",
       "      <td>95.481928</td>\n",
       "      <td>Charlotte-Concord-Gastonia, NC-SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7673379</td>\n",
       "      <td>3984437</td>\n",
       "      <td>92.583770</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7142603</td>\n",
       "      <td>3767335</td>\n",
       "      <td>89.592988</td>\n",
       "      <td>Houston-The Woodlands-Sugar Land, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2570862</td>\n",
       "      <td>1407745</td>\n",
       "      <td>82.622705</td>\n",
       "      <td>San Antonio-New Braunfels, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1990873</td>\n",
       "      <td>1103028</td>\n",
       "      <td>80.491610</td>\n",
       "      <td>Nashville-Davidson--Murfreesboro--Franklin, TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2959386</td>\n",
       "      <td>1650489</td>\n",
       "      <td>79.303588</td>\n",
       "      <td>Denver-Aurora-Lakewood, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4610050</td>\n",
       "      <td>2588793</td>\n",
       "      <td>78.077197</td>\n",
       "      <td>Riverside-San Bernardino-Ontario, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1613587</td>\n",
       "      <td>925213</td>\n",
       "      <td>74.401678</td>\n",
       "      <td>Jacksonville, FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2505312</td>\n",
       "      <td>1523741</td>\n",
       "      <td>64.418494</td>\n",
       "      <td>Portland-Vancouver-Hillsboro, OR-WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2394673</td>\n",
       "      <td>1481102</td>\n",
       "      <td>61.681842</td>\n",
       "      <td>Sacramento-Roseville-Folsom, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4001701</td>\n",
       "      <td>2559164</td>\n",
       "      <td>56.367509</td>\n",
       "      <td>Seattle-Tacoma-Bellevue, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6346083</td>\n",
       "      <td>4105955</td>\n",
       "      <td>54.558026</td>\n",
       "      <td>Washington-Arlington-Alexandria, DC-VA-MD-WV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3194310</td>\n",
       "      <td>2067959</td>\n",
       "      <td>54.466796</td>\n",
       "      <td>Tampa-St. Petersburg-Clearwater, FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2109957</td>\n",
       "      <td>1410690</td>\n",
       "      <td>49.569147</td>\n",
       "      <td>Indianapolis-Carmel-Anderson, IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2137223</td>\n",
       "      <td>1462258</td>\n",
       "      <td>46.159091</td>\n",
       "      <td>Columbus, OH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3678328</td>\n",
       "      <td>2580743</td>\n",
       "      <td>42.529806</td>\n",
       "      <td>Minneapolis-St. Paul-Bloomington, MN-WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2190750</td>\n",
       "      <td>1614534</td>\n",
       "      <td>35.689307</td>\n",
       "      <td>Kansas City, MO-KS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3289701</td>\n",
       "      <td>2498016</td>\n",
       "      <td>31.692551</td>\n",
       "      <td>San Diego-Chula Vista-Carlsbad, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1981584</td>\n",
       "      <td>1534274</td>\n",
       "      <td>29.154506</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4692242</td>\n",
       "      <td>3686592</td>\n",
       "      <td>27.278581</td>\n",
       "      <td>San Francisco-Oakland-Berkeley, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1798025</td>\n",
       "      <td>1464598</td>\n",
       "      <td>22.765769</td>\n",
       "      <td>Virginia Beach-Norfolk-Newport News, VA-NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2253528</td>\n",
       "      <td>1844917</td>\n",
       "      <td>22.147934</td>\n",
       "      <td>Cincinnati, OH-KY-IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2840005</td>\n",
       "      <td>2382172</td>\n",
       "      <td>19.219141</td>\n",
       "      <td>Baltimore-Columbia-Towson, MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4912449</td>\n",
       "      <td>4133895</td>\n",
       "      <td>18.833425</td>\n",
       "      <td>Boston-Cambridge-Newton, MA-NH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9566955</td>\n",
       "      <td>8053895</td>\n",
       "      <td>18.786686</td>\n",
       "      <td>Chicago-Naperville-Elgin, IL-IN-WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>19908595</td>\n",
       "      <td>16818080</td>\n",
       "      <td>18.376146</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13111917</td>\n",
       "      <td>11273720</td>\n",
       "      <td>16.305150</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6232894</td>\n",
       "      <td>5435468</td>\n",
       "      <td>14.670788</td>\n",
       "      <td>Philadelphia-Camden-Wilmington, PA-NJ-DE-MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1670949</td>\n",
       "      <td>1509789</td>\n",
       "      <td>10.674339</td>\n",
       "      <td>Providence-Warwick, RI-MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2813523</td>\n",
       "      <td>2560517</td>\n",
       "      <td>9.881051</td>\n",
       "      <td>St. Louis, MO-IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1568940</td>\n",
       "      <td>1432149</td>\n",
       "      <td>9.551450</td>\n",
       "      <td>Milwaukee-Waukesha, WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4375604</td>\n",
       "      <td>4248699</td>\n",
       "      <td>2.986914</td>\n",
       "      <td>Detroit-Warren-Dearborn, MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2365501</td>\n",
       "      <td>2564535</td>\n",
       "      <td>-7.761017</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pop2022   pop1990  growth_percentage  \\\n",
       "0    2265926    741459         205.603681   \n",
       "1    6123949   2119006         189.001022   \n",
       "2    2296377    846227         171.366548   \n",
       "3    2679298   1224852         118.744632   \n",
       "4    4864209   2238480         117.299641   \n",
       "5    6094752   3083843          97.634964   \n",
       "6    2668688   1365184          95.481928   \n",
       "7    7673379   3984437          92.583770   \n",
       "8    7142603   3767335          89.592988   \n",
       "9    2570862   1407745          82.622705   \n",
       "10   1990873   1103028          80.491610   \n",
       "11   2959386   1650489          79.303588   \n",
       "12   4610050   2588793          78.077197   \n",
       "13   1613587    925213          74.401678   \n",
       "14   2505312   1523741          64.418494   \n",
       "15   2394673   1481102          61.681842   \n",
       "16   4001701   2559164          56.367509   \n",
       "17   6346083   4105955          54.558026   \n",
       "18   3194310   2067959          54.466796   \n",
       "19   2109957   1410690          49.569147   \n",
       "20   2137223   1462258          46.159091   \n",
       "21   3678328   2580743          42.529806   \n",
       "22   2190750   1614534          35.689307   \n",
       "23   3289701   2498016          31.692551   \n",
       "24   1981584   1534274          29.154506   \n",
       "25   4692242   3686592          27.278581   \n",
       "26   1798025   1464598          22.765769   \n",
       "27   2253528   1844917          22.147934   \n",
       "28   2840005   2382172          19.219141   \n",
       "29   4912449   4133895          18.833425   \n",
       "30   9566955   8053895          18.786686   \n",
       "31  19908595  16818080          18.376146   \n",
       "32  13111917  11273720          16.305150   \n",
       "33   6232894   5435468          14.670788   \n",
       "34   1670949   1509789          10.674339   \n",
       "35   2813523   2560517           9.881051   \n",
       "36   1568940   1432149           9.551450   \n",
       "37   4375604   4248699           2.986914   \n",
       "38   2365501   2564535          -7.761017   \n",
       "\n",
       "                                          geo_name  \n",
       "0                 Las Vegas-Henderson-Paradise, NV  \n",
       "1          Miami-Fort Lauderdale-Pompano Beach, FL  \n",
       "2                 Austin-Round Rock-Georgetown, TX  \n",
       "3                    Orlando-Kissimmee-Sanford, FL  \n",
       "4                        Phoenix-Mesa-Chandler, AZ  \n",
       "5             Atlanta-Sandy Springs-Alpharetta, GA  \n",
       "6                Charlotte-Concord-Gastonia, NC-SC  \n",
       "7                  Dallas-Fort Worth-Arlington, TX  \n",
       "8             Houston-The Woodlands-Sugar Land, TX  \n",
       "9                    San Antonio-New Braunfels, TX  \n",
       "10  Nashville-Davidson--Murfreesboro--Franklin, TN  \n",
       "11                      Denver-Aurora-Lakewood, CO  \n",
       "12            Riverside-San Bernardino-Ontario, CA  \n",
       "13                                Jacksonville, FL  \n",
       "14             Portland-Vancouver-Hillsboro, OR-WA  \n",
       "15                 Sacramento-Roseville-Folsom, CA  \n",
       "16                     Seattle-Tacoma-Bellevue, WA  \n",
       "17    Washington-Arlington-Alexandria, DC-VA-MD-WV  \n",
       "18             Tampa-St. Petersburg-Clearwater, FL  \n",
       "19                Indianapolis-Carmel-Anderson, IN  \n",
       "20                                    Columbus, OH  \n",
       "21         Minneapolis-St. Paul-Bloomington, MN-WI  \n",
       "22                              Kansas City, MO-KS  \n",
       "23              San Diego-Chula Vista-Carlsbad, CA  \n",
       "24              San Jose-Sunnyvale-Santa Clara, CA  \n",
       "25              San Francisco-Oakland-Berkeley, CA  \n",
       "26      Virginia Beach-Norfolk-Newport News, VA-NC  \n",
       "27                            Cincinnati, OH-KY-IN  \n",
       "28                   Baltimore-Columbia-Towson, MD  \n",
       "29                  Boston-Cambridge-Newton, MA-NH  \n",
       "30              Chicago-Naperville-Elgin, IL-IN-WI  \n",
       "31           New York-Newark-Jersey City, NY-NJ-PA  \n",
       "32              Los Angeles-Long Beach-Anaheim, CA  \n",
       "33     Philadelphia-Camden-Wilmington, PA-NJ-DE-MD  \n",
       "34                       Providence-Warwick, RI-MA  \n",
       "35                                St. Louis, MO-IL  \n",
       "36                          Milwaukee-Waukesha, WI  \n",
       "37                     Detroit-Warren-Dearborn, MI  \n",
       "38                                  Pittsburgh, PA  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter acs population data to only keep CBSAs with population 1,500,000 or greater\n",
    "xf = xf[(xf['year'] == 2022) & \n",
    "                 (xf['geo_id'].str.startswith('c')) & \n",
    "                 (xf['population'] >= 1500000)]\n",
    "xf = xf.rename(columns={'population':'pop2022'})\n",
    "cbsa_large_list = xf['geo_id'].unique().tolist()\n",
    "\n",
    "# filter decennial population data to county-level\n",
    "df = df[df['geo_id'].str.len()==5]\n",
    "# merge in CBSA codes for counties within CBSAs\n",
    "df = df.merge(xwalk, left_on='geo_id', right_on='county', how='inner') # inner merge so that only counties inside of CBSAs remain (and no counties outside CBSAs)\n",
    "df = df.drop(columns=['geo_id', 'county'])\n",
    "df = df.rename(columns={'cbsa':'geo_id', 'population':'pop1990'})\n",
    "\n",
    "# groupby CBSA\n",
    "df = df.groupby(['geo_id', 'year']).sum().reset_index()\n",
    "df = df[df['year'].isin([1990])]\n",
    "df = df[df['geo_id'].isin(cbsa_large_list)]\n",
    "\n",
    "# merge dataframes on 'geo_id'\n",
    "merged_df = pd.merge(xf, df, on=\"geo_id\", how=\"inner\")\n",
    "\n",
    "# calculate population growth percentage\n",
    "merged_df['growth_percentage'] = ((merged_df['pop2022'] - merged_df['pop1990']) / merged_df['pop1990']) * 100\n",
    "\n",
    "# Display the merged dataFrame with the new column\n",
    "merged_df = merged_df.sort_values(by='growth_percentage', ascending=False)\n",
    "xwalk = pd.read_csv(url_prefix + 'resources/geo_relatedgeo_crosswalk.csv', converters={'geo_id':str})\n",
    "xwalk = xwalk[['geo_id', 'geo_name']]\n",
    "xwalk.drop_duplicates(inplace=True, keep='last')\n",
    "merged_df = merged_df.merge(xwalk, on='geo_id')\n",
    "merged_df.drop(columns=['geo_id', 'year_x', 'year_y'], inplace=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export completed dataframe to folder\n",
    "file_path = 'DO_completed_csvs/figure1_5.csv'\n",
    "title = 'Source: Decennial 1990 & ACS 2022 Population'\n",
    "merged_df.to_csv(file_path, index=False)\n",
    "\n",
    "# append the data source to the dataframe\n",
    "with open(file_path, 'a') as f:\n",
    "    f.write('\\n' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Figure 7: City of Dallas Household Size (2012-2022) [p.28]\n",
    "**Source:**  B25009 (American Communities Survey)\n",
    "\n",
    "**Note:** Place definitions have changed since 1990. We use a reference here named 1990_places to match the old definitions to new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull data\n",
    "df = filter_dataset(\n",
    "    dataset_name = 'ACS_B25009_HouseholdSize',\n",
    "    geography_set = [geography_city],\n",
    "    years = [2012,2022]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Dallas_1_person_household</th>\n",
       "      <th>Dallas_2_person_household</th>\n",
       "      <th>Dallas_3_person_household</th>\n",
       "      <th>Dallas_4_person_household</th>\n",
       "      <th>Dallas_5_person_household</th>\n",
       "      <th>Dallas_6_person_household</th>\n",
       "      <th>Dallas_7_Inf_person_household</th>\n",
       "      <th>Dallas_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>158396</td>\n",
       "      <td>129595</td>\n",
       "      <td>63345</td>\n",
       "      <td>53095</td>\n",
       "      <td>28925</td>\n",
       "      <td>13570</td>\n",
       "      <td>10045</td>\n",
       "      <td>456971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>191742</td>\n",
       "      <td>153849</td>\n",
       "      <td>66683</td>\n",
       "      <td>53630</td>\n",
       "      <td>33812</td>\n",
       "      <td>13032</td>\n",
       "      <td>8399</td>\n",
       "      <td>521147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  Dallas_1_person_household  Dallas_2_person_household  \\\n",
       "0  2012                     158396                     129595   \n",
       "1  2022                     191742                     153849   \n",
       "\n",
       "   Dallas_3_person_household  Dallas_4_person_household  \\\n",
       "0                      63345                      53095   \n",
       "1                      66683                      53630   \n",
       "\n",
       "   Dallas_5_person_household  Dallas_6_person_household  \\\n",
       "0                      28925                      13570   \n",
       "1                      33812                      13032   \n",
       "\n",
       "   Dallas_7_Inf_person_household  Dallas_all  \n",
       "0                          10045      456971  \n",
       "1                           8399      521147  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.merge(names, on='geo_id')\n",
    "\n",
    "# transpose dataframe\n",
    "df_pivoted = df.pivot(index='year', columns='household_size', values='households')\n",
    "geo_name = df['geo_name'].iloc[0]\n",
    "df_pivoted.columns = [f\"{geo_name}_{col}\" for col in df_pivoted.columns]\n",
    "df_pivoted.reset_index(inplace=True)\n",
    "df_pivoted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'DO_completed_csvs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDO_completed_csvs/figure1_7.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource: ACS 2012 & 2022 B25009_HouseholdSize\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdf_pivoted\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# append the data source to the dataframe\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'DO_completed_csvs'"
     ]
    }
   ],
   "source": [
    "# export completed dataframe to folder\n",
    "file_path = 'DO_completed_csvs/figure1_7.csv'\n",
    "title = 'Source: ACS 2012 & 2022 B25009_HouseholdSize'\n",
    "df_pivoted.to_csv(file_path, index=False)\n",
    "\n",
    "# append the data source to the dataframe\n",
    "with open(file_path, 'a') as f:\n",
    "    f.write('\\n' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Figure 8: Average Household Size (2012-2022) [p.28]\n",
    "**Source:**  B25010 (American Communities Survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>geo_name</th>\n",
       "      <th>Dallas</th>\n",
       "      <th>Dallas County</th>\n",
       "      <th>Dallas-Fort Worth-Arlington, TX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.60</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.60</td>\n",
       "      <td>2.77</td>\n",
       "      <td>2.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.61</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.60</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.58</td>\n",
       "      <td>2.77</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.58</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.57</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.56</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.52</td>\n",
       "      <td>2.74</td>\n",
       "      <td>2.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.49</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.46</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "geo_name  Dallas  Dallas County  Dallas-Fort Worth-Arlington, TX\n",
       "0           2.60           2.76                             2.77\n",
       "1           2.60           2.77                             2.78\n",
       "2           2.61           2.78                             2.79\n",
       "3           2.60           2.79                             2.80\n",
       "4           2.58           2.77                             2.80\n",
       "5           2.58           2.78                             2.81\n",
       "6           2.57           2.79                             2.83\n",
       "7           2.56           2.78                             2.83\n",
       "8           2.52           2.74                             2.82\n",
       "9           2.49           2.72                             2.77\n",
       "10          2.46           2.68                             2.75"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull data\n",
    "df = filter_dataset(\n",
    "    dataset_name = 'ACS_B25010_AverageHouseholdSize',\n",
    "    geography_set = [geography_city,geography_metro,geography_county],\n",
    "    years = [2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022]\n",
    ")\n",
    "xf = df.sort_values(\"year\").reset_index(drop=True)\n",
    "xf = xf.merge(names, on='geo_id')\n",
    "\n",
    "# clean and pivot dataframe\n",
    "pivot_df = xf.pivot(index='year', columns='geo_name', values='average_household_size')\n",
    "pivot_df.reset_index(drop=True, inplace=True)\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'DO_completed_csvs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDO_completed_csvs/figure1_8.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource: ACS 2012 & 2022 B25009_HouseholdSize\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mpivot_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# append the data source to the dataframe\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'DO_completed_csvs'"
     ]
    }
   ],
   "source": [
    "# export completed dataframe to folder\n",
    "file_path = 'DO_completed_csvs/figure1_8.csv'\n",
    "title = 'Source: ACS 2012 & 2022 B25009_HouseholdSize'\n",
    "pivot_df.to_csv(file_path, index=True)\n",
    "\n",
    "# append the data source to the dataframe\n",
    "with open(file_path, 'a') as f:\n",
    "    f.write('\\n' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 9: Net Out-Migrants from Dallas County to other Metro Counties (2011-2021) [p.28]\n",
    "\n",
    "**Source:** IRS Data (Next release is 6/27/24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_name</th>\n",
       "      <th>out_hh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Collin County</td>\n",
       "      <td>231523.493497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denton County</td>\n",
       "      <td>175383.245551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellis County</td>\n",
       "      <td>44254.229244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hunt County</td>\n",
       "      <td>14021.775471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Johnson County</td>\n",
       "      <td>7512.823438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kaufman County</td>\n",
       "      <td>53860.641419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rockwall County</td>\n",
       "      <td>32770.163956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tarrant County</td>\n",
       "      <td>241524.213093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          geo_name         out_hh\n",
       "0    Collin County  231523.493497\n",
       "1    Denton County  175383.245551\n",
       "2     Ellis County   44254.229244\n",
       "3      Hunt County   14021.775471\n",
       "4   Johnson County    7512.823438\n",
       "5   Kaufman County   53860.641419\n",
       "6  Rockwall County   32770.163956\n",
       "7   Tarrant County  241524.213093"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file containing IRS data for out-migrants, ensuring 'geo_id' is read as string\n",
    "df = pd.read_csv(url_prefix + '230912_IRS_Data_Top.csv', converters={'geo_id': str})\n",
    "\n",
    "# Keep only the rows where the flow is 'outflow', indicating out-migration\n",
    "df = df[df['flow'] == 'outflow']\n",
    "\n",
    "# Define the geography of the county of interest\n",
    "origin = [geography_county]\n",
    "\n",
    "# Ensure the 'geo_id' column is of type string (this may be redundant due to the converter)\n",
    "df['geo_id'] = df['geo_id'].astype(str)\n",
    "\n",
    "# Filter the dataframe to include only the specified origin counties\n",
    "df = df[df['geo_id'].isin(origin)]\n",
    "\n",
    "# Ensure the 'related_geo_id' column is of type string\n",
    "df['related_geo_id'] = df['related_geo_id'].astype(str)\n",
    "\n",
    "# List of destination counties in Texas (as strings of their geo IDs)\n",
    "destination = ['48121', '48085', '48231', '48439', '48397', '48257', '48139', '48251']\n",
    "\n",
    "# Filter the dataframe to include only the specified destination counties\n",
    "df = df[df['related_geo_id'].isin(destination)]\n",
    "\n",
    "# Merge the dataframe with another dataframe 'names' to associate geo IDs with geographic names\n",
    "df = df.merge(names, left_on='related_geo_id', right_on='geo_id')\n",
    "\n",
    "# Calculate the number of out-migrant households using individual counts and average household size\n",
    "df['out_hh'] = df['number_individuals'] / df['avg_hh_size']\n",
    "\n",
    "# Group by geographic name and sum the out-migrant households for each destination\n",
    "df = df.groupby('geo_name', as_index=False).agg({'out_hh': 'sum'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "references/DFW_counties.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mfiona/ogrext.pyx:136\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: references/DFW_counties.shp: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### This dataset will be mapped in the next step.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#buffer for map boundaries\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m dallas_counties \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreferences/DFW_counties.shp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m dallas_counties[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNTY_NM\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dallas_counties[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCNTY_NM\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m County\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m dallas_dissolve \u001b[38;5;241m=\u001b[39m dallas_counties\u001b[38;5;241m.\u001b[39mdissolve()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/geopandas/io/file.py:289\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m         path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_fiona\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown engine \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/geopandas/io/file.py:315\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     reader \u001b[38;5;241m=\u001b[39m fiona\u001b[38;5;241m.\u001b[39mopen\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fiona_env():\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m features:\n\u001b[1;32m    316\u001b[0m         crs \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcrs_wkt\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;66;03m# attempt to get EPSG code\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fiona/env.py:457\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    454\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fiona/__init__.py:292\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m     path \u001b[38;5;241m=\u001b[39m parse_path(fp)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m \u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43menabled_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menabled_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    303\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[1;32m    304\u001b[0m         path,\n\u001b[1;32m    305\u001b[0m         mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    315\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fiona/collection.py:243\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m Session()\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m WritingSession()\n",
      "File \u001b[0;32mfiona/ogrext.pyx:588\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:143\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: references/DFW_counties.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "### This dataset will be mapped in the next step.\n",
    "\n",
    "#buffer for map boundaries\n",
    "dallas_counties = gpd.read_file('references/DFW_counties.shp')\n",
    "dallas_counties['CNTY_NM'] = dallas_counties['CNTY_NM'] + ' County'\n",
    "dallas_dissolve = dallas_counties.dissolve()\n",
    "dallas_buffer = dallas_counties.centroid.buffer(35000)\n",
    "factor = 8000\n",
    "\n",
    "#basemap\n",
    "bmap = 'references/masked_basemap.tif'\n",
    "\n",
    "# Merge dataframe and shapefile on the county column\n",
    "merged_gdf = dallas_counties.merge(df, left_on='CNTY_NM', right_on='geo_name')\n",
    "\n",
    "# Ensure the CRS is set to EPSG:3857 for plotting with Contextily\n",
    "merged_gdf = merged_gdf.to_crs(epsg=3857)\n",
    "\n",
    "# Plot the choropleth map\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "merged_gdf.plot(ax=ax, alpha=0.7, edgecolor='black', \n",
    "                column='out_hh', cmap='OrRd',\n",
    "                linewidth=2, linestyle ='dashed', legend=True)\n",
    "\n",
    "# Calculate bounds for setting the view limits based on merged_gdf\n",
    "minx, miny, maxx, maxy = merged_gdf.total_bounds\n",
    "factor = 0.02 * (maxx - minx)  # Adjust factor for margins\n",
    "\n",
    "ax.set_xlim(minx - factor, maxx + factor)\n",
    "ax.set_ylim(miny - factor, maxy + factor)\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Add a basemap\n",
    "cx.add_basemap(ax, crs=merged_gdf.crs.to_string(), source=bmap, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'DO_completed_csvs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDO_completed_csvs/figure1_9.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource: IRS 2021 Out-migrants by income\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdf_pivoted\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# append the data source to the dataframe\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'DO_completed_csvs'"
     ]
    }
   ],
   "source": [
    "# export completed dataframe to folder\n",
    "file_path = 'DO_completed_csvs/figure1_9.csv'\n",
    "title = 'Source: IRS 2021 Out-migrants by income'\n",
    "df_pivoted.to_csv(file_path, index=False)\n",
    "\n",
    "# append the data source to the dataframe\n",
    "with open(file_path, 'a') as f:\n",
    "    f.write('\\n' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 10: Household size of in-migrants versus out-migrants (2021) [p.28]\n",
    "\n",
    "**Source:** IRS Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/p4h692fs2850l4jh7f7_qq9r0000gr/T/ipykernel_30879/3966517186.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_df['out_hh'] = (out_df['number_individuals']) / (out_df['avg_hh_size'])\n",
      "/var/folders/y1/p4h692fs2850l4jh7f7_qq9r0000gr/T/ipykernel_30879/3966517186.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  in_df['related_geo_id'] = in_df['related_geo_id'].astype(str)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_out_hh</th>\n",
       "      <th>mean_in_hh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2774.217093</td>\n",
       "      <td>508.769248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_out_hh  mean_in_hh\n",
       "0  2774.217093  508.769248"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Figure 10: Household size of in-migrants versus out-migrants (2021) [p.28]\n",
    "\n",
    "# pull data\n",
    "df = pd.read_csv(url_prefix + '230912_IRS_Data_Top.csv', converters = {'geo_id':str})\n",
    "\n",
    "## out-migrants: filter to 2021 & only outflow from Dallas County\n",
    "out_df = df[(df['year'].isin([2021])) & (df['flow'] == 'outflow') & (df['geo_id'] == geography_county)]\n",
    "out_df['out_hh'] = (out_df['number_individuals']) / (out_df['avg_hh_size'])\n",
    "\n",
    "# in-migrants: filter to 2021 & only outflow from Dallas County\n",
    "in_df = df[(df['year'].isin([2021])) & (df['flow'] == 'inflow')]\n",
    "destination = [geography_county]\n",
    "in_df['related_geo_id'] = in_df['related_geo_id'].astype(str)\n",
    "in_df = in_df[in_df['related_geo_id'].isin(destination)]\n",
    "in_df['in_hh'] = (in_df['number_individuals']) / (in_df['avg_hh_size'])\n",
    "\n",
    "# calculate the mean of 'out_hh' from out_df\n",
    "mean_out_hh = out_df['out_hh'].mean()\n",
    "\n",
    "# calculate the mean of 'in_hh' from in_df\n",
    "mean_in_hh = in_df['in_hh'].mean()\n",
    "\n",
    "# create a new dataframe with these means\n",
    "mean_df = pd.DataFrame({\n",
    "    'mean_out_hh': [mean_out_hh],\n",
    "    'mean_in_hh': [mean_in_hh]\n",
    "})\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export completed dataframe to folder\n",
    "file_path = 'DO_completed_csvs/figure1_10.csv'\n",
    "title = 'Source: IRS 2021 Out-migrants by income'\n",
    "mean_df.to_csv(file_path, index=False)\n",
    "\n",
    "# append the data source to the dataframe\n",
    "with open(file_path, 'a') as f:\n",
    "    f.write('\\n' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 12: City of Dallas Age Distribution (2012-2022)[p.30]\n",
    "\n",
    "**Source:** B01001 (American Communities Survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">population</th>\n",
       "      <th colspan=\"3\" halign=\"left\">total_population</th>\n",
       "      <th colspan=\"3\" halign=\"left\">percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>2012</th>\n",
       "      <th>2017</th>\n",
       "      <th>2022</th>\n",
       "      <th>2012</th>\n",
       "      <th>2017</th>\n",
       "      <th>2022</th>\n",
       "      <th>2012</th>\n",
       "      <th>2017</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_cat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17 and under</th>\n",
       "      <td>316586.0</td>\n",
       "      <td>332020.0</td>\n",
       "      <td>317057.0</td>\n",
       "      <td>1207202.0</td>\n",
       "      <td>1300122.0</td>\n",
       "      <td>1300642.0</td>\n",
       "      <td>26.224774</td>\n",
       "      <td>25.537603</td>\n",
       "      <td>24.376962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18 to 34</th>\n",
       "      <td>350361.0</td>\n",
       "      <td>371496.0</td>\n",
       "      <td>372467.0</td>\n",
       "      <td>1207202.0</td>\n",
       "      <td>1300122.0</td>\n",
       "      <td>1300642.0</td>\n",
       "      <td>29.022566</td>\n",
       "      <td>28.573934</td>\n",
       "      <td>28.637165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35 to 64</th>\n",
       "      <td>431755.0</td>\n",
       "      <td>468984.0</td>\n",
       "      <td>467626.0</td>\n",
       "      <td>1207202.0</td>\n",
       "      <td>1300122.0</td>\n",
       "      <td>1300642.0</td>\n",
       "      <td>35.764934</td>\n",
       "      <td>36.072307</td>\n",
       "      <td>35.953475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65 and over</th>\n",
       "      <td>108500.0</td>\n",
       "      <td>127622.0</td>\n",
       "      <td>143492.0</td>\n",
       "      <td>1207202.0</td>\n",
       "      <td>1300122.0</td>\n",
       "      <td>1300642.0</td>\n",
       "      <td>8.987725</td>\n",
       "      <td>9.816156</td>\n",
       "      <td>11.032398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             population                     total_population             \\\n",
       "year               2012      2017      2022             2012       2017   \n",
       "age_cat                                                                   \n",
       "17 and under   316586.0  332020.0  317057.0        1207202.0  1300122.0   \n",
       "18 to 34       350361.0  371496.0  372467.0        1207202.0  1300122.0   \n",
       "35 to 64       431755.0  468984.0  467626.0        1207202.0  1300122.0   \n",
       "65 and over    108500.0  127622.0  143492.0        1207202.0  1300122.0   \n",
       "\n",
       "                        percentage                        \n",
       "year               2022       2012       2017       2022  \n",
       "age_cat                                                   \n",
       "17 and under  1300642.0  26.224774  25.537603  24.376962  \n",
       "18 to 34      1300642.0  29.022566  28.573934  28.637165  \n",
       "35 to 64      1300642.0  35.764934  36.072307  35.953475  \n",
       "65 and over   1300642.0   8.987725   9.816156  11.032398  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull data\n",
    "df = filter_dataset(\n",
    "    dataset_name = 'ACS_B01001_AgeDistribution',\n",
    "    geography_set = ['4819000'],\n",
    "    years = [2012,2017,2022]\n",
    ")\n",
    "df = df[df['age_range'] != '25+']\n",
    "df = df.merge(names, on='geo_id')\n",
    "\n",
    "# map the existing age ranges to the new categories\n",
    "age_mapping = {\n",
    "    '0_17': '17 and under',\n",
    "    '18_24': '18 to 34',\n",
    "    '25_34': '18 to 34',\n",
    "    '35_64': '35 to 64',\n",
    "    '65_Inf': '65 and over'\n",
    "}\n",
    "\n",
    "# apply the mapping to the age_range column\n",
    "df['age_cat'] = df['age_range'].map(age_mapping)\n",
    "\n",
    "# group by the new age range and other relevant columns, and sum the population\n",
    "grouped_df = df.groupby(['geo_name', 'year', 'age_cat'])['population'].sum().reset_index()\n",
    "\n",
    "# calculate total population by year without merging it back\n",
    "grouped_df['total_population'] = grouped_df.groupby('year')['population'].transform('sum')\n",
    "\n",
    "# calculate the percentage\n",
    "grouped_df['percentage'] = (grouped_df['population'] / grouped_df['total_population']) * 100\n",
    "\n",
    "pivoted_df = grouped_df.pivot(index='age_cat', columns='year', values=['population', 'total_population', 'percentage'])\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'DO_completed_csvs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDO_completed_csvs/figure1_12.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource: ACS 2012 & 2022 B01001_AgeDistribution\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mpivoted_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# append the data source to the dataframe\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'DO_completed_csvs'"
     ]
    }
   ],
   "source": [
    "# export completed dataframe to folder\n",
    "file_path = 'DO_completed_csvs/figure1_12.csv'\n",
    "title = 'Source: ACS 2012 & 2022 B01001_AgeDistribution'\n",
    "pivoted_df.to_csv(file_path, index=True)\n",
    "\n",
    "# append the data source to the dataframe\n",
    "with open(file_path, 'a') as f:\n",
    "    f.write('\\n' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 13: Comparative Age Distribution (2022)[p.30]\n",
    "**Source:** B01001 (American Communities Survey) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">population</th>\n",
       "      <th colspan=\"3\" halign=\"left\">total_population</th>\n",
       "      <th colspan=\"3\" halign=\"left\">percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>2012</th>\n",
       "      <th>2017</th>\n",
       "      <th>2022</th>\n",
       "      <th>2012</th>\n",
       "      <th>2017</th>\n",
       "      <th>2022</th>\n",
       "      <th>2012</th>\n",
       "      <th>2017</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_cat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17 and under</th>\n",
       "      <td>316586.0</td>\n",
       "      <td>332020.0</td>\n",
       "      <td>317057.0</td>\n",
       "      <td>1207202.0</td>\n",
       "      <td>1300122.0</td>\n",
       "      <td>1300642.0</td>\n",
       "      <td>26.224774</td>\n",
       "      <td>25.537603</td>\n",
       "      <td>24.376962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18 to 34</th>\n",
       "      <td>350361.0</td>\n",
       "      <td>371496.0</td>\n",
       "      <td>372467.0</td>\n",
       "      <td>1207202.0</td>\n",
       "      <td>1300122.0</td>\n",
       "      <td>1300642.0</td>\n",
       "      <td>29.022566</td>\n",
       "      <td>28.573934</td>\n",
       "      <td>28.637165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35 to 64</th>\n",
       "      <td>431755.0</td>\n",
       "      <td>468984.0</td>\n",
       "      <td>467626.0</td>\n",
       "      <td>1207202.0</td>\n",
       "      <td>1300122.0</td>\n",
       "      <td>1300642.0</td>\n",
       "      <td>35.764934</td>\n",
       "      <td>36.072307</td>\n",
       "      <td>35.953475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65 and over</th>\n",
       "      <td>108500.0</td>\n",
       "      <td>127622.0</td>\n",
       "      <td>143492.0</td>\n",
       "      <td>1207202.0</td>\n",
       "      <td>1300122.0</td>\n",
       "      <td>1300642.0</td>\n",
       "      <td>8.987725</td>\n",
       "      <td>9.816156</td>\n",
       "      <td>11.032398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             population                     total_population             \\\n",
       "year               2012      2017      2022             2012       2017   \n",
       "age_cat                                                                   \n",
       "17 and under   316586.0  332020.0  317057.0        1207202.0  1300122.0   \n",
       "18 to 34       350361.0  371496.0  372467.0        1207202.0  1300122.0   \n",
       "35 to 64       431755.0  468984.0  467626.0        1207202.0  1300122.0   \n",
       "65 and over    108500.0  127622.0  143492.0        1207202.0  1300122.0   \n",
       "\n",
       "                        percentage                        \n",
       "year               2022       2012       2017       2022  \n",
       "age_cat                                                   \n",
       "17 and under  1300642.0  26.224774  25.537603  24.376962  \n",
       "18 to 34      1300642.0  29.022566  28.573934  28.637165  \n",
       "35 to 64      1300642.0  35.764934  36.072307  35.953475  \n",
       "65 and over   1300642.0   8.987725   9.816156  11.032398  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map the existing age ranges to the new categories\n",
    "age_mapping = {\n",
    "    '0_17': '17 and under',\n",
    "    '18_24': '18 to 34',\n",
    "    '25_34': '18 to 34',\n",
    "    '35_64': '35 to 64',\n",
    "    '65_Inf': '65 and over'\n",
    "}\n",
    "\n",
    "# apply the mapping to the age_range column\n",
    "df['age_cat'] = df['age_range'].map(age_mapping)\n",
    "\n",
    "# group by the new age range and other relevant columns, and sum the population\n",
    "grouped_df = df.groupby(['geo_name', 'year', 'age_cat'])['population'].sum().reset_index()\n",
    "\n",
    "# calculate total population by year without merging it back\n",
    "grouped_df['total_population'] = grouped_df.groupby('year')['population'].transform('sum')\n",
    "\n",
    "# calculate the percentage\n",
    "grouped_df['percentage'] = (grouped_df['population'] / grouped_df['total_population']) * 100\n",
    "\n",
    "pivoted_df = grouped_df.pivot(index='age_cat', columns='year', values=['population', 'total_population', 'percentage'])\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pivoted_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDO_completed_csvs/figure1_13.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource: ACS 2012-20022 B01001_AgeDistribution\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mpivoted_df\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# append the data source to the dataframe\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pivoted_df' is not defined"
     ]
    }
   ],
   "source": [
    "# export completed dataframe to folder\n",
    "file_path = 'DO_completed_csvs/figure1_13.csv'\n",
    "title = 'Source: ACS 2012-20022 B01001_AgeDistribution'\n",
    "pivoted_df.to_csv(file_path, index=True)\n",
    "\n",
    "# append the data source to the dataframe\n",
    "with open(file_path, 'a') as f:\n",
    "    f.write('\\n' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 14: Median Income Change (2012-2022)[p.31]\n",
    "**Source:** B19013 (American Communities Survey) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>year</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_income_2022$</th>\n",
       "      <th>geo_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c19100</td>\n",
       "      <td>2012</td>\n",
       "      <td>58190.0</td>\n",
       "      <td>75220.0</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4835000</td>\n",
       "      <td>2012</td>\n",
       "      <td>44648.0</td>\n",
       "      <td>57715.0</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4819000</td>\n",
       "      <td>2012</td>\n",
       "      <td>42436.0</td>\n",
       "      <td>54855.0</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4805000</td>\n",
       "      <td>2012</td>\n",
       "      <td>52431.0</td>\n",
       "      <td>67776.0</td>\n",
       "      <td>Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48113</td>\n",
       "      <td>2012</td>\n",
       "      <td>49159.0</td>\n",
       "      <td>63546.0</td>\n",
       "      <td>Dallas County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>48</td>\n",
       "      <td>2022</td>\n",
       "      <td>73035.0</td>\n",
       "      <td>73035.0</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>c19100</td>\n",
       "      <td>2022</td>\n",
       "      <td>83398.0</td>\n",
       "      <td>83398.0</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4805000</td>\n",
       "      <td>2022</td>\n",
       "      <td>86556.0</td>\n",
       "      <td>86556.0</td>\n",
       "      <td>Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4819000</td>\n",
       "      <td>2022</td>\n",
       "      <td>63985.0</td>\n",
       "      <td>63985.0</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4835000</td>\n",
       "      <td>2022</td>\n",
       "      <td>60440.0</td>\n",
       "      <td>60440.0</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     geo_id  year  median_income  median_income_2022$  \\\n",
       "0    c19100  2012        58190.0              75220.0   \n",
       "1   4835000  2012        44648.0              57715.0   \n",
       "2   4819000  2012        42436.0              54855.0   \n",
       "3   4805000  2012        52431.0              67776.0   \n",
       "4     48113  2012        49159.0              63546.0   \n",
       "..      ...   ...            ...                  ...   \n",
       "61       48  2022        73035.0              73035.0   \n",
       "62   c19100  2022        83398.0              83398.0   \n",
       "63  4805000  2022        86556.0              86556.0   \n",
       "64  4819000  2022        63985.0              63985.0   \n",
       "65  4835000  2022        60440.0              60440.0   \n",
       "\n",
       "                           geo_name  \n",
       "0   Dallas-Fort Worth-Arlington, TX  \n",
       "1                           Houston  \n",
       "2                            Dallas  \n",
       "3                            Austin  \n",
       "4                     Dallas County  \n",
       "..                              ...  \n",
       "61                            Texas  \n",
       "62  Dallas-Fort Worth-Arlington, TX  \n",
       "63                           Austin  \n",
       "64                           Dallas  \n",
       "65                          Houston  \n",
       "\n",
       "[66 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull data\n",
    "austin = '4805000'\n",
    "houston = '4835000'\n",
    "texas = '48'\n",
    "df = filter_dataset(\n",
    "    dataset_name = 'ACS_B19013_MedianHouseholdIncome_inflation_adjust',\n",
    "    geography_set = [geography_county,geography_city,geography_metro, austin, houston, texas],\n",
    "    years = [2012, 2013, 2014, 2015, 2016 , 2017, 2018, 2019, 2020, 2021, 2022]\n",
    ")\n",
    "df = df.sort_values(\"year\").reset_index(drop=True)\n",
    "df = df.merge(names, on='geo_id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>geo_name</th>\n",
       "      <th colspan=\"11\" halign=\"left\">median_income_2022$</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austin</td>\n",
       "      <td>67776.0</td>\n",
       "      <td>68702.0</td>\n",
       "      <td>69792.0</td>\n",
       "      <td>72389.0</td>\n",
       "      <td>74913.0</td>\n",
       "      <td>76711.0</td>\n",
       "      <td>79697.0</td>\n",
       "      <td>82668.0</td>\n",
       "      <td>86316.0</td>\n",
       "      <td>84062.0</td>\n",
       "      <td>86556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>54855.0</td>\n",
       "      <td>54566.0</td>\n",
       "      <td>54805.0</td>\n",
       "      <td>54937.0</td>\n",
       "      <td>55584.0</td>\n",
       "      <td>56928.0</td>\n",
       "      <td>59186.0</td>\n",
       "      <td>60728.0</td>\n",
       "      <td>62381.0</td>\n",
       "      <td>61989.0</td>\n",
       "      <td>63985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dallas County</td>\n",
       "      <td>63546.0</td>\n",
       "      <td>63016.0</td>\n",
       "      <td>63104.0</td>\n",
       "      <td>63080.0</td>\n",
       "      <td>63201.0</td>\n",
       "      <td>64562.0</td>\n",
       "      <td>67165.0</td>\n",
       "      <td>68844.0</td>\n",
       "      <td>70498.0</td>\n",
       "      <td>69207.0</td>\n",
       "      <td>70732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>75220.0</td>\n",
       "      <td>74319.0</td>\n",
       "      <td>74796.0</td>\n",
       "      <td>75222.0</td>\n",
       "      <td>75394.0</td>\n",
       "      <td>76895.0</td>\n",
       "      <td>79130.0</td>\n",
       "      <td>81172.0</td>\n",
       "      <td>83045.0</td>\n",
       "      <td>81880.0</td>\n",
       "      <td>83398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Houston</td>\n",
       "      <td>57715.0</td>\n",
       "      <td>57322.0</td>\n",
       "      <td>57799.0</td>\n",
       "      <td>57957.0</td>\n",
       "      <td>57790.0</td>\n",
       "      <td>59473.0</td>\n",
       "      <td>60415.0</td>\n",
       "      <td>60449.0</td>\n",
       "      <td>61074.0</td>\n",
       "      <td>59635.0</td>\n",
       "      <td>60440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texas</td>\n",
       "      <td>66654.0</td>\n",
       "      <td>66097.0</td>\n",
       "      <td>66455.0</td>\n",
       "      <td>66765.0</td>\n",
       "      <td>67277.0</td>\n",
       "      <td>68685.0</td>\n",
       "      <td>70374.0</td>\n",
       "      <td>71463.0</td>\n",
       "      <td>72727.0</td>\n",
       "      <td>71666.0</td>\n",
       "      <td>73035.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             geo_name median_income_2022$                    \\\n",
       "year                                                 2012     2013     2014   \n",
       "0                              Austin             67776.0  68702.0  69792.0   \n",
       "1                              Dallas             54855.0  54566.0  54805.0   \n",
       "2                       Dallas County             63546.0  63016.0  63104.0   \n",
       "3     Dallas-Fort Worth-Arlington, TX             75220.0  74319.0  74796.0   \n",
       "4                             Houston             57715.0  57322.0  57799.0   \n",
       "5                               Texas             66654.0  66097.0  66455.0   \n",
       "\n",
       "                                                                              \n",
       "year     2015     2016     2017     2018     2019     2020     2021     2022  \n",
       "0     72389.0  74913.0  76711.0  79697.0  82668.0  86316.0  84062.0  86556.0  \n",
       "1     54937.0  55584.0  56928.0  59186.0  60728.0  62381.0  61989.0  63985.0  \n",
       "2     63080.0  63201.0  64562.0  67165.0  68844.0  70498.0  69207.0  70732.0  \n",
       "3     75222.0  75394.0  76895.0  79130.0  81172.0  83045.0  81880.0  83398.0  \n",
       "4     57957.0  57790.0  59473.0  60415.0  60449.0  61074.0  59635.0  60440.0  \n",
       "5     66765.0  67277.0  68685.0  70374.0  71463.0  72727.0  71666.0  73035.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose dataframe\n",
    "df = df.pivot_table(index='geo_name', columns='year', values=['median_income_2022$'])\n",
    "df.reset_index(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export completed dataframe to folder\n",
    "file_path = 'DO_completed_csvs/figure1_14.csv'\n",
    "title = 'Source: ACS 2012 & 2022 B19013_MedianHouseholdIncome'\n",
    "\n",
    "# append the data source to the dataframe\n",
    "df.to_csv(file_path, index=True)\n",
    "\n",
    "# Append the title to the CSV\n",
    "with open(file_path, 'a') as f:\n",
    "    f.write('\\n' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 15: Comparative Median Income (2012-2022, $ change, pct change) [p.31]\n",
    "**Source:** B19013 (American Communities Survey) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>year</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_income_2022$</th>\n",
       "      <th>geo_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>2012</td>\n",
       "      <td>51563.0</td>\n",
       "      <td>66654.0</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48113</td>\n",
       "      <td>2012</td>\n",
       "      <td>49159.0</td>\n",
       "      <td>63546.0</td>\n",
       "      <td>Dallas County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4805000</td>\n",
       "      <td>2012</td>\n",
       "      <td>52431.0</td>\n",
       "      <td>67776.0</td>\n",
       "      <td>Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4819000</td>\n",
       "      <td>2012</td>\n",
       "      <td>42436.0</td>\n",
       "      <td>54855.0</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4835000</td>\n",
       "      <td>2012</td>\n",
       "      <td>44648.0</td>\n",
       "      <td>57715.0</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c19100</td>\n",
       "      <td>2012</td>\n",
       "      <td>58190.0</td>\n",
       "      <td>75220.0</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48113</td>\n",
       "      <td>2022</td>\n",
       "      <td>70732.0</td>\n",
       "      <td>70732.0</td>\n",
       "      <td>Dallas County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4805000</td>\n",
       "      <td>2022</td>\n",
       "      <td>86556.0</td>\n",
       "      <td>86556.0</td>\n",
       "      <td>Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4819000</td>\n",
       "      <td>2022</td>\n",
       "      <td>63985.0</td>\n",
       "      <td>63985.0</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4835000</td>\n",
       "      <td>2022</td>\n",
       "      <td>60440.0</td>\n",
       "      <td>60440.0</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>48</td>\n",
       "      <td>2022</td>\n",
       "      <td>73035.0</td>\n",
       "      <td>73035.0</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c19100</td>\n",
       "      <td>2022</td>\n",
       "      <td>83398.0</td>\n",
       "      <td>83398.0</td>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     geo_id  year  median_income  median_income_2022$  \\\n",
       "0        48  2012        51563.0              66654.0   \n",
       "1     48113  2012        49159.0              63546.0   \n",
       "2   4805000  2012        52431.0              67776.0   \n",
       "3   4819000  2012        42436.0              54855.0   \n",
       "4   4835000  2012        44648.0              57715.0   \n",
       "5    c19100  2012        58190.0              75220.0   \n",
       "6     48113  2022        70732.0              70732.0   \n",
       "7   4805000  2022        86556.0              86556.0   \n",
       "8   4819000  2022        63985.0              63985.0   \n",
       "9   4835000  2022        60440.0              60440.0   \n",
       "10       48  2022        73035.0              73035.0   \n",
       "11   c19100  2022        83398.0              83398.0   \n",
       "\n",
       "                           geo_name  \n",
       "0                             Texas  \n",
       "1                     Dallas County  \n",
       "2                            Austin  \n",
       "3                            Dallas  \n",
       "4                           Houston  \n",
       "5   Dallas-Fort Worth-Arlington, TX  \n",
       "6                     Dallas County  \n",
       "7                            Austin  \n",
       "8                            Dallas  \n",
       "9                           Houston  \n",
       "10                            Texas  \n",
       "11  Dallas-Fort Worth-Arlington, TX  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pull data\n",
    "austin = '4805000'\n",
    "houston = '4835000'\n",
    "texas = '48'\n",
    "\n",
    "df = filter_dataset(\n",
    "    dataset_name = 'ACS_B19013_MedianHouseholdIncome_inflation_adjust',\n",
    "    geography_set = [geography_county,geography_city,geography_metro, austin, houston, texas],\n",
    "    years = [2012, 2022]\n",
    ")\n",
    "df = df.sort_values(\"year\").reset_index(drop=True)\n",
    "df = df.merge(names, on='geo_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_name</th>\n",
       "      <th>median_income_2012</th>\n",
       "      <th>median_income_2022</th>\n",
       "      <th>dollar_change</th>\n",
       "      <th>percentage_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Texas</td>\n",
       "      <td>66654.0</td>\n",
       "      <td>73035.0</td>\n",
       "      <td>6381.0</td>\n",
       "      <td>9.573319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dallas County</td>\n",
       "      <td>63546.0</td>\n",
       "      <td>70732.0</td>\n",
       "      <td>7186.0</td>\n",
       "      <td>11.308344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austin</td>\n",
       "      <td>67776.0</td>\n",
       "      <td>86556.0</td>\n",
       "      <td>18780.0</td>\n",
       "      <td>27.708924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>54855.0</td>\n",
       "      <td>63985.0</td>\n",
       "      <td>9130.0</td>\n",
       "      <td>16.643879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Houston</td>\n",
       "      <td>57715.0</td>\n",
       "      <td>60440.0</td>\n",
       "      <td>2725.0</td>\n",
       "      <td>4.721476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dallas-Fort Worth-Arlington, TX</td>\n",
       "      <td>75220.0</td>\n",
       "      <td>83398.0</td>\n",
       "      <td>8178.0</td>\n",
       "      <td>10.872108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          geo_name  median_income_2012  median_income_2022  \\\n",
       "0                            Texas             66654.0             73035.0   \n",
       "1                    Dallas County             63546.0             70732.0   \n",
       "2                           Austin             67776.0             86556.0   \n",
       "3                           Dallas             54855.0             63985.0   \n",
       "4                          Houston             57715.0             60440.0   \n",
       "5  Dallas-Fort Worth-Arlington, TX             75220.0             83398.0   \n",
       "\n",
       "   dollar_change  percentage_change  \n",
       "0         6381.0           9.573319  \n",
       "1         7186.0          11.308344  \n",
       "2        18780.0          27.708924  \n",
       "3         9130.0          16.643879  \n",
       "4         2725.0           4.721476  \n",
       "5         8178.0          10.872108  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataframe for calculation\n",
    "df_2012 = df[df['year'] == 2012]\n",
    "df_2022 = df[df['year'] == 2022]\n",
    "\n",
    "# merge dataframes to compare median incomes in 2012 and 2022\n",
    "merged_df = pd.merge(df_2012, df_2022, on='geo_id', suffixes=('_2012', '_2022'))\n",
    "\n",
    "# calculate dollar and percentage change\n",
    "merged_df['dollar_change'] = merged_df['median_income_2022$_2022'] - merged_df['median_income_2022$_2012']\n",
    "merged_df['percentage_change'] = ((merged_df['median_income_2022$_2022'] - merged_df['median_income_2022$_2012']) / merged_df['median_income_2022$_2012']) * 100\n",
    "\n",
    "# rename columns to remove suffixes\n",
    "merged_df.rename(columns={'geo_name_2012': 'geo_name', 'median_income_2012': 'unadjusted2012', 'median_income_2022': 'unadjusted2022', 'median_income_2022$_2012': 'median_income_2012', 'median_income_2022$_2022': 'median_income_2022'}, inplace=True)\n",
    "\n",
    "# rearrange columns and drop unnecessary columns\n",
    "final_df = merged_df[['geo_name', 'median_income_2012', 'median_income_2022', 'dollar_change', 'percentage_change']]\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export completed dataframe to folder\n",
    "file_path = 'DO_completed_csvs/figure1_15.csv'\n",
    "title = 'Source: ACS 2012 & 2022 B19013_MedianHouseholdIncome'\n",
    "final_df.to_csv(file_path, index=False)\n",
    "\n",
    "# append the data source to the dataframe\n",
    "with open(file_path, 'a') as f:\n",
    "    f.write('\\n' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 17: Comparative Household Distribution by Race/Ethnicity (2022) [p.33]\n",
    "Source: ACS_B25003A, Tenure By Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IncompleteRead",
     "evalue": "IncompleteRead(69920111 bytes read, 397406826 more expected)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pull data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mACS_B25003A_TenureByRace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeography_set\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mgeography_city\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeography_metro\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43myears\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2012\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2022\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m xf \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m xf \u001b[38;5;241m=\u001b[39m xf\u001b[38;5;241m.\u001b[39mmerge(names, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeo_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m, in \u001b[0;36mfilter_dataset\u001b[0;34m(dataset_name, geography_set, years)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter_dataset\u001b[39m(dataset_name, geography_set, years):\n\u001b[0;32m----> 2\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_prefix\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeo_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeo_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(geography_set)) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(years))]\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/repos/cpal-hna-report/cpal/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/cpal-hna-report/cpal/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/repos/cpal-hna-report/cpal/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/cpal-hna-report/cpal/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/repos/cpal-hna-report/cpal/lib/python3.12/site-packages/pandas/io/common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m~/repos/cpal-hna-report/cpal/lib/python3.12/site-packages/pandas/io/common.py:389\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n\u001b[1;32m    388\u001b[0m             compression \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m--> 389\u001b[0m         reader \u001b[38;5;241m=\u001b[39m BytesIO(\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m IOArgs(\n\u001b[1;32m    391\u001b[0m         filepath_or_buffer\u001b[38;5;241m=\u001b[39mreader,\n\u001b[1;32m    392\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m         mode\u001b[38;5;241m=\u001b[39mfsspec_mode,\n\u001b[1;32m    396\u001b[0m     )\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_fsspec_url(filepath_or_buffer):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:495\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead:\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/http/client.py:642\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    640\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[0;32m--> 642\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(69920111 bytes read, 397406826 more expected)"
     ]
    }
   ],
   "source": [
    "# pull data\n",
    "df = filter_dataset(\n",
    "    dataset_name = 'ACS_B25003A_TenureByRace',\n",
    "    geography_set = [geography_city, geography_metro],\n",
    "    years = [2012,2022]\n",
    ")\n",
    "xf = df.sort_values(\"year\").reset_index(drop=True)\n",
    "xf = xf.merge(names, on='geo_id')\n",
    "xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the necessary identifiers\n",
    "xf = xf.groupby(['geo_id', 'year', 'tenure', 'geo_name', 'race']).agg({'households': 'sum'}).reset_index()\n",
    "\n",
    "# Add the 'native_american_or_pacific_islander' households to 'other'\n",
    "other_mask = xf['race'] == 'other'\n",
    "napi_mask = xf['race'] == 'native_american_or_pacific_islander'\n",
    "\n",
    "for index, row in xf[napi_mask].iterrows():\n",
    "    matching_index = xf[other_mask & (xf['geo_id'] == row['geo_id']) & (xf['year'] == row['year']) & (xf['tenure'] == row['tenure']) & (xf['geo_name'] == row['geo_name'])].index\n",
    "    if not matching_index.empty:\n",
    "        xf.loc[matching_index, 'households'] += row['households']\n",
    "\n",
    "# Remove 'native_american_or_pacific_islander' entries\n",
    "xf = xf[xf['race'] != 'native_american_or_pacific_islander']\n",
    "\n",
    "# rename 'race' column values\n",
    "race_mapping = {\n",
    "    'asian': 'Asian',\n",
    "    'black': 'Black',\n",
    "    'hispanic': 'Hispanic/Latino',\n",
    "    'other': 'Other',\n",
    "    'white': 'Non-hispanic White'\n",
    "}\n",
    "\n",
    "# replace the 'race' column values based on the mapping\n",
    "xf['race'] = xf['race'].replace(race_mapping)\n",
    "xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = xf[xf['year']=='2022']\n",
    "# group by 'geo_name' and 'race', then sum 'households' for each group\n",
    "df = df.groupby(['geo_name', 'race'])['households'].sum().reset_index()\n",
    "# calculate the total number of households per geo_name\n",
    "df['total_per_geo'] = df.groupby('geo_name')['households'].transform('sum')\n",
    "# calculate the percentage of each race in its geo_name\n",
    "df['percentage'] = (df['households'] / df['total_per_geo'])\n",
    "pivoted_df = df.pivot(index='race', columns='geo_name', values=['households', 'total_per_geo', 'percentage'])\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export completed dataframe to folder\n",
    "file_path = 'DO_completed_csvs/figure1_17.csv'\n",
    "title = 'Source: ACS 2022 B25003A_TenureByRace'\n",
    "pivoted_df.to_csv(file_path, index=True)\n",
    "\n",
    "# append the data source to the dataframe\n",
    "with open(file_path, 'a') as f:\n",
    "    f.write('\\n' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 18: City of Dallas Households by Race/Ethnicity(2012-2022, totals, change, pct change) [p.33]\n",
    "Source: ACS_B25003A, Tenure By Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull data\n",
    "df = filter_dataset(\n",
    "    dataset_name = 'ACS_B25003A_TenureByRace',\n",
    "    geography_set = [geography_city],\n",
    "    years = [2012, 2022]\n",
    ")\n",
    "df = df.sort_values(\"year\").reset_index(drop=True)\n",
    "df = df.merge(names, on='geo_id')\n",
    "df\n",
    "\n",
    "# Group by the necessary identifiers\n",
    "df = df.groupby(['geo_id', 'year', 'tenure', 'geo_name', 'race']).agg({'households': 'sum'}).reset_index()\n",
    "\n",
    "# Add the 'native_american_or_pacific_islander' households to 'other'\n",
    "other_mask = df['race'] == 'other'\n",
    "napi_mask = df['race'] == 'native_american_or_pacific_islander'\n",
    "\n",
    "for index, row in df[napi_mask].iterrows():\n",
    "    matching_index = df[other_mask & (df['geo_id'] == row['geo_id']) & (df['year'] == row['year']) & (df['tenure'] == row['tenure']) & (df['geo_name'] == row['geo_name'])].index\n",
    "    if not matching_index.empty:\n",
    "        df.loc[matching_index, 'households'] += row['households']\n",
    "\n",
    "# Remove 'native_american_or_pacific_islander' entries\n",
    "df = df[df['race'] != 'native_american_or_pacific_islander']\n",
    "\n",
    "# rename 'race' column values\n",
    "race_mapping = {\n",
    "    'asian': 'Asian',\n",
    "    'black': 'Black',\n",
    "    'hispanic': 'Hispanic/Latino',\n",
    "    'other': 'Other',\n",
    "    'white': 'Non-hispanic White'\n",
    "}\n",
    "\n",
    "# replace the 'race' column values based on the mapping\n",
    "df['race'] = df['race'].replace(race_mapping)\n",
    "df = df.groupby(['year', 'geo_name', 'race'])['households'].sum().reset_index()\n",
    "\n",
    "# restructure dataframe for calculation\n",
    "df_pivot = grouped.pivot_table(index=['geo_name', 'race'], columns='year', values='households', fill_value=0)\n",
    "\n",
    "# rename the columns for clarity\n",
    "df_pivot.columns = [f'households_{year}' for year in df_pivot.columns]\n",
    "\n",
    "# calculate the number change and percentage change\n",
    "df_pivot['hh_change'] = df_pivot['households_2022'] - df_pivot['households_2012']\n",
    "df_pivot['percentage_change'] = (df_pivot['hh_change'] / df_pivot['households_2012'])\n",
    "\n",
    "df_pivot.reset_index(inplace=True)\n",
    "df_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export completed dataframe to folder\n",
    "file_path = 'DO_completed_csvs/figure1_18.csv'\n",
    "title = 'Source: ACS 2012 & 2022 B25003A_TenureByRace'\n",
    "df_pivot.to_csv(file_path, index=True)\n",
    "\n",
    "# append the data source to the dataframe\n",
    "with open(file_path, 'a') as f:\n",
    "    f.write('\\n' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 19: City of Dallas Household Distribution by Race/Ethnicity (2022, totals, pct) [p.33]\n",
    "Source: ACS_B25003A, Tenure By Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Figure 24: Dissimilarity Index, Census Tract Level (2022) [p.34]\n",
    "\n",
    "df = pd.read_csv(url_prefix + 'Calculated_FromACS_DissimilarityIndex.csv', converters = {'geo_id':str})\n",
    "xf = pd.read_csv(url_prefix + 'ACS_B01003_Population.csv', converters = {'geo_id':str})\n",
    "df = df.merge(names, on='geo_id')\n",
    "\n",
    "# filter to only keep geographies that are places, with population above 500K,  and year = 2022\n",
    "xf = xf[(xf['year'] == 2022) & (xf['geo_id'].str.len() == 7) & (xf['population'] >= 500000)]\n",
    "GEOID = xf['geo_id'].unique()\n",
    "df = df[df['geo_id'].isin(GEOID)]\n",
    "df = df.sort_values(\"DissimilarityIndex\", ascending = False).reset_index(drop=True)\n",
    "df = df.drop(columns=['geo_id'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export completed dataframe to folder\n",
    "file_path = 'DO_completed_csvs/figure1_24.csv'\n",
    "title = 'Source: ACS 2022 Dissimilarity Index & Population'\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# append the data source to the dataframe\n",
    "with open(file_path, 'a') as f:\n",
    "    f.write('\\n' + title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 25: City of Dallas Median Income by Race/Ethnicity (2012-2022) [p.35]\n",
    "Source: ACS B19013H Median Household Income by Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull data\n",
    "df = filter_dataset(\n",
    "    dataset_name = 'ACS_B19013H_MedianHouseholdIncomeByRace_inflation_adjust',\n",
    "    geography_set = [geography_city],\n",
    "    years = [2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    ")\n",
    "df = df.sort_values(\"year\").reset_index(drop=True)\n",
    "df = df.merge(names, on='geo_id')\n",
    "\n",
    "# Define the categories to combine\n",
    "combine_categories = ['native_american', 'pacific_islander', 'some_other_race', 'two_or_more_races']\n",
    "\n",
    "# Create a new column for 'race' where specified categories are labeled as 'Other'\n",
    "df['race'] = df['race'].apply(lambda x: 'Other' if x in combine_categories else x)\n",
    "\n",
    "# Group by 'year' and 'race', then calculate the median of the incomes\n",
    "df = df.groupby(['year', 'race'], as_index=False)['median_income_2022$'].median()\n",
    "\n",
    "pivoted_df = df_grouped.pivot_table(index=\"race\", columns=\"year\", values=\"median_income_2022$\", aggfunc='first')\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export completed dataframe to folder\n",
    "file_path = 'DO_completed_csvs/figure1_25.csv'\n",
    "title = 'Source: ACS 2012 & 2022 B19013H_MedianHouseholdIncomeByRace'\n",
    "pivoted_df.to_csv(file_path, index=True)\n",
    "\n",
    "# append the data source to the dataframe\n",
    "with open(file_path, 'a') as f:\n",
    "    f.write('\\n' + title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
